{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading local data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = listdir(\"../chart\")\n",
    "\n",
    "dfs_chart = {}\n",
    "for f in files:\n",
    "    year = int(f.split(\"_\")[0])\n",
    "    month = f.split(\"_\")[1].split(\".\")[0]\n",
    "\n",
    "    if dfs_chart.get(year) is None:\n",
    "        dfs_chart[year] = {}\n",
    "        \n",
    "    dfs_chart[year][month] = pd.read_csv(\"../chart/\" + f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supression des dernière column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1 in dfs_chart.keys():\n",
    "    for k2 in dfs_chart[k1].keys():\n",
    "        dfs_chart[k1][k2].drop(columns=[\"Naissance\", \"Pays d'origine\", \"Origine\", \"Pays\", \"Nationalité\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2004, 2023, 1)\n",
    "weeks = [int(v) for v in np.linspace(1, 52, 12)]\n",
    "mois = [\"Janvier\", \"Fevrier\", \"Mars\", \"Avril\", \"Mai\", \"Juin\", \"Juillet\", \"Aout\", \"Septembre\", \"Octobre\", \"Novembre\", \"Decembre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:54<00:00,  9.20s/it]\n"
     ]
    }
   ],
   "source": [
    "dfs_chart = {y : {} for y in years}\n",
    "for y in tqdm(years):\n",
    "    for k, w in enumerate(weeks):\n",
    "        url = f\"https://acharts.co/france_singles_top_100/{y}/{w}\"\n",
    "        rq = get(url)\n",
    "        m = mois[k]\n",
    "        if rq.ok:\n",
    "            soup = BeautifulSoup(rq.text)\n",
    "\n",
    "            chart = soup.find(\"table\", {\"id\" : \"ChartTable\"})\n",
    "            trs = chart.findAll(\"tr\")[1:]\n",
    "\n",
    "            data = []\n",
    "            for tr in trs:\n",
    "                music_name = tr.find(\"span\", {\"itemprop\" : \"name\"}).text\n",
    "                rank = tr.find(\"span\", {\"itemprop\" : \"position\"}).text\n",
    "                artist_name = tr.find(\"span\", {\"itemprop\" : \"byArtist\"}).text[2:-1]\n",
    "                data.append([rank, artist_name, music_name])\n",
    "\n",
    "            df = pd.DataFrame(data, columns=[\"Rank\", \"Artist\", \"Music\"])\n",
    "            dfs_chart[y][m] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1 in dfs_chart.keys():\n",
    "    for k2 in dfs_chart[k1].keys():\n",
    "        dfs_chart[k1][k2].replace(\"Djadja\", \"Djadja et Dinaz\", inplace=True)\n",
    "        dfs_chart[k1][k2].replace(\"Lorie\", \"Lorie Pester\", inplace=True)\n",
    "        dfs_chart[k1][k2].replace(\"-M-\", \"Matthieu Chedid\", inplace=True)\n",
    "        dfs_chart[k1][k2].replace(\"Priscilla\", \"Priscilla Betti\", inplace=True)\n",
    "        dfs_chart[k1][k2].replace(\"Brigitte\", \"Brigitte (groupe)\", inplace=True)\n",
    "        dfs_chart[k1][k2].replace(\"I Am\", \"IAM\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "from nltk.metrics.distance import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MISSING = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_title_in_wikipedia(title):\n",
    "    words = [\"(chanteur)\", \"(chanteuse)\", \"(groupe)\", \"(rappeur)\", \"(rappeuse)\", \"(musicien)\", \"(chanteur français)\"]\n",
    "\n",
    "    wikipedia.set_lang(\"fr\")\n",
    "    results = wikipedia.search(title, results=10)\n",
    "    distance = []\n",
    "    if len(results) > 0:\n",
    "        for element in results:\n",
    "            if any(w in element for w in words):\n",
    "                return element\n",
    "\n",
    "            distance.append(edit_distance(title, element))\n",
    "\n",
    "        return results[np.argmin(distance)]\n",
    "\n",
    "    return MISSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(l):\n",
    "    return \" \".join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_birth(title):\n",
    "    cols = [\"Naissance\", \"Pays d'origine\", \"Origine\", \"Nationalité\", \"Pays\"]\n",
    "    nats = [\"francophone\", \"français\", \"belge\", \"canadien\", \"libanais\", \"réunionnais\"]\n",
    "    dic = {w : MISSING for w in cols}\n",
    "\n",
    "    if title == MISSING:\n",
    "        return dic\n",
    "\n",
    "    url = f\"https://fr.wikipedia.org/wiki/{title}\"\n",
    "    rq = get(url)\n",
    "\n",
    "    if not rq.ok:\n",
    "        return dic\n",
    "    \n",
    "    soup = BeautifulSoup(rq.text)\n",
    "    tables = soup.findAll(\"table\")\n",
    "\n",
    "    for table in tables:\n",
    "        trs = table.findAll(\"tr\")\n",
    "\n",
    "        for tr in trs:\n",
    "            th = tr.find(\"th\")\n",
    "\n",
    "            if th is not None:\n",
    "                for w in cols:\n",
    "                    if w in th.text:\n",
    "                        td = tr.find(\"td\")\n",
    "                        if td is not None:\n",
    "                            dic[w] = td.text.strip()\n",
    "\n",
    "    if not all(x == \" \" for x in dic.values()):\n",
    "        return dic\n",
    "    else:\n",
    "        wikipedia.set_lang(\"fr\")\n",
    "        try:\n",
    "            summary = wikipedia.summary(title, sentences=1)\n",
    "            for w in nats:\n",
    "                if w in summary:\n",
    "                    dic[\"Nationalité\"] = w\n",
    "                    return dic\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = []\n",
    "for k1 in dfs_chart.keys():\n",
    "    for k2 in dfs_chart[k1].keys():\n",
    "        artist += dfs_chart[k1][k2][\"Artist\"].tolist()\n",
    "    \n",
    "artist = pd.DataFrame(list(set(artist)), columns=[\"Artist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist[\"Artist_wiki\"] = artist[\"Artist\"].apply(find_title_in_wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\quent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    }
   ],
   "source": [
    "birth_dic = artist[\"Artist_wiki\"].apply(wiki_birth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_birth = []\n",
    "for dic in birth_dic:\n",
    "    dfs_birth.append(pd.DataFrame(dic, index=[0]))\n",
    "birth = pd.concat(dfs_birth, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = artist.merge(birth, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist.drop(columns=[\"Artist_wiki\"], inplace=True)\n",
    "artist = artist.set_index(\"Artist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1 in dfs_chart.keys():\n",
    "    for k2 in dfs_chart[k1].keys():\n",
    "        dfs_chart[k1][k2] = dfs_chart[k1][k2].join(artist, on=\"Artist\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1 in dfs_chart.keys():\n",
    "    for k2 in dfs_chart[k1].keys():\n",
    "        dfs_chart[k1][k2].to_csv(f\"../chart/{k1}_{k2}.csv\", encoding=\"utf-8-sig\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = artist[\n",
    "    (artist[\"Naissance\"] == MISSING) & \n",
    "    (artist[\"Pays d'origine\"] == MISSING) & \n",
    "    (artist[\"Origine\"] == MISSING) & \n",
    "    (artist[\"Nationalité\"] == MISSING) & \n",
    "    (artist[\"Pays\"] == MISSING)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for k1 in dfs_chart.keys():\n",
    "    for k2 in dfs_chart[k1].keys():\n",
    "        dfs.append(dfs_chart[k1][k2])\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Rank\"], inplace=True)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"MISSING\"] = (\n",
    "    (df[\"Naissance\"] == MISSING) &\n",
    "    (df[\"Pays d'origine\"] == MISSING) &\n",
    "    (df[\"Origine\"] == MISSING) &\n",
    "    (df[\"Nationalité\"] == MISSING) &\n",
    "    (df[\"Pays\"] == MISSING)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Artist\n",
       "Landy                    12\n",
       "Eva                      11\n",
       "Swedish House Mafia       6\n",
       "Sound Of Legend           6\n",
       "Justice                   5\n",
       "Pigloo                    5\n",
       "Le 6-9                    5\n",
       "Basto!                    4\n",
       "Soma Riba                 4\n",
       "Blue                      4\n",
       "Glk                       4\n",
       "Dry                       4\n",
       "Feder                     4\n",
       "Cauet                     4\n",
       "Titou Le Lapinou          4\n",
       "Kore                      3\n",
       "Charlotte Aux Fraises     3\n",
       "Gullia                    3\n",
       "Far*east Movement         3\n",
       "Sasso                     3\n",
       "Name: MISSING, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"Artist\")[\"MISSING\"].sum().sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Music</th>\n",
       "      <th>Naissance</th>\n",
       "      <th>Pays d'origine</th>\n",
       "      <th>Origine</th>\n",
       "      <th>Nationalité</th>\n",
       "      <th>Pays</th>\n",
       "      <th>MISSING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Artist, Music, Naissance, Pays d'origine, Origine, Nationalité, Pays, MISSING]\n",
       "Index: []"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Artist\"] == \"I Am\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2823d83d0138f4e88bebb1ac6893599dadbc35aa0bdabe1fb606adea8faab8b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
