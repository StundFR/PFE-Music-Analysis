{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import wikipedia\n",
    "from nltk.metrics.distance import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MISSING = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading local data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Récupére les données sur le PC pour éviter de scrapper à chaque fois\n",
    "files = listdir(\"../chart\")\n",
    "\n",
    "dfs_chart = {}\n",
    "for f in files:\n",
    "    year = f.split(\"_\")[0]\n",
    "    month = f.split(\"_\")[1].split(\".\")[0]\n",
    "\n",
    "    if dfs_chart.get(year) is None:\n",
    "        dfs_chart[year] = {}\n",
    "        \n",
    "    dfs_chart[year][month] = pd.read_csv(\"../chart/\" + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Music</th>\n",
       "      <th>Artist_wiki</th>\n",
       "      <th>Naissance</th>\n",
       "      <th>Pays d'origine</th>\n",
       "      <th>Origine</th>\n",
       "      <th>Nationalité</th>\n",
       "      <th>Pays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Juanes</td>\n",
       "      <td>La Camisa Negra</td>\n",
       "      <td>Juanes</td>\n",
       "      <td>9 août 1972 (50 ans)Medellin,  Colombie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Madonna</td>\n",
       "      <td>Hung Up</td>\n",
       "      <td>Madonna</td>\n",
       "      <td>16 août 1958 (64 ans)Bay City, Michigan (États...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Américaine</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Johnny Hallyday</td>\n",
       "      <td>Mon Plus Beau Noël</td>\n",
       "      <td>Johnny Hallyday</td>\n",
       "      <td>15 juin 1943 Paris 9e (France)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Française</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank           Artist               Music      Artist_wiki  \\\n",
       "0     1           Juanes     La Camisa Negra           Juanes   \n",
       "1     2          Madonna             Hung Up          Madonna   \n",
       "2     3  Johnny Hallyday  Mon Plus Beau Noël  Johnny Hallyday   \n",
       "\n",
       "                                           Naissance Pays d'origine Origine  \\\n",
       "0            9 août 1972 (50 ans)Medellin,  Colombie            NaN     NaN   \n",
       "1  16 août 1958 (64 ans)Bay City, Michigan (États...            NaN     NaN   \n",
       "2                     15 juin 1943 Paris 9e (France)            NaN     NaN   \n",
       "\n",
       "  Nationalité Pays  \n",
       "0         NaN  NaN  \n",
       "1  Américaine  NaN  \n",
       "2   Française  NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_chart[\"2006\"][\"Janvier\"].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = pd.read_csv(\"../artist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Artist_wiki</th>\n",
       "      <th>Naissance</th>\n",
       "      <th>Pays d'origine</th>\n",
       "      <th>Origine</th>\n",
       "      <th>Nationalité</th>\n",
       "      <th>Pays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anuel Aa</td>\n",
       "      <td>Anuel AA</td>\n",
       "      <td>26 novembre 1992 (30 ans)Carolina (Porto Rico)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>portoricaine</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Childish Gambino</td>\n",
       "      <td>This Is America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tydiaz</td>\n",
       "      <td>Foire de Châlons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lucenzo</td>\n",
       "      <td>Lucenzo</td>\n",
       "      <td>27 mai 1983 (39 ans)Bordeaux, France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris Garcia</td>\n",
       "      <td>Dany Garcia</td>\n",
       "      <td>29 novembre 1968 (54 ans)Belleville</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>américaine</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>Radio Killer</td>\n",
       "      <td>Radio Killer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>Star Academy Maghreb</td>\n",
       "      <td>Star Academy (Maghreb)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>Mr. Oizo</td>\n",
       "      <td>Nonfilm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>Cee-lo Green</td>\n",
       "      <td>Cee Lo Green</td>\n",
       "      <td>30 mai 1974 (48 ans)[1],[2]Atlanta, Géorgie,  ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>Gotye</td>\n",
       "      <td>Gotye</td>\n",
       "      <td>21 mai 1980 (42 ans)Bruges,  Belgique</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2272 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Artist             Artist_wiki  \\\n",
       "0                 Anuel Aa                Anuel AA   \n",
       "1         Childish Gambino         This Is America   \n",
       "2                   Tydiaz        Foire de Châlons   \n",
       "3                  Lucenzo                 Lucenzo   \n",
       "4             Chris Garcia             Dany Garcia   \n",
       "...                    ...                     ...   \n",
       "2267          Radio Killer            Radio Killer   \n",
       "2268  Star Academy Maghreb  Star Academy (Maghreb)   \n",
       "2269              Mr. Oizo                 Nonfilm   \n",
       "2270          Cee-lo Green            Cee Lo Green   \n",
       "2271                 Gotye                   Gotye   \n",
       "\n",
       "                                              Naissance Pays d'origine  \\\n",
       "0        26 novembre 1992 (30 ans)Carolina (Porto Rico)            NaN   \n",
       "1                                                   NaN            NaN   \n",
       "2                                                   NaN            NaN   \n",
       "3                  27 mai 1983 (39 ans)Bordeaux, France            NaN   \n",
       "4                   29 novembre 1968 (54 ans)Belleville            NaN   \n",
       "...                                                 ...            ...   \n",
       "2267                                                NaN            NaN   \n",
       "2268                                                NaN            NaN   \n",
       "2269                                                NaN            NaN   \n",
       "2270  30 mai 1974 (48 ans)[1],[2]Atlanta, Géorgie,  ...            NaN   \n",
       "2271              21 mai 1980 (42 ans)Bruges,  Belgique            NaN   \n",
       "\n",
       "     Origine   Nationalité    Pays  \n",
       "0        NaN  portoricaine     NaN  \n",
       "1        NaN           NaN     NaN  \n",
       "2        NaN           NaN     NaN  \n",
       "3        NaN           NaN     NaN  \n",
       "4        NaN    américaine     NaN  \n",
       "...      ...           ...     ...  \n",
       "2267     NaN           NaN     NaN  \n",
       "2268     NaN           NaN     NaN  \n",
       "2269     NaN           NaN  france  \n",
       "2270     NaN           NaN     NaN  \n",
       "2271     NaN           NaN     NaN  \n",
       "\n",
       "[2272 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supression des dernières columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supprime les dernières colonnes pour relancer le scrapping sur wikipédia\n",
    "for k1 in dfs_chart.keys():\n",
    "    for k2 in dfs_chart[k1].keys():\n",
    "        dfs_chart[k1][k2].drop(columns=[\"Naissance\", \"Pays d'origine\", \"Origine\", \"Pays\", \"Nationalité\", \"Artist_wiki\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Music</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Juanes</td>\n",
       "      <td>La Camisa Negra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Madonna</td>\n",
       "      <td>Hung Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Johnny Hallyday</td>\n",
       "      <td>Mon Plus Beau Noël</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank           Artist               Music\n",
       "0     1           Juanes     La Camisa Negra\n",
       "1     2          Madonna             Hung Up\n",
       "2     3  Johnny Hallyday  Mon Plus Beau Noël"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_chart[\"2006\"][\"Janvier\"].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Artist_wiki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anuel Aa</td>\n",
       "      <td>Anuel AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Childish Gambino</td>\n",
       "      <td>This Is America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tydiaz</td>\n",
       "      <td>Foire de Châlons</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Artist       Artist_wiki\n",
       "0          Anuel Aa          Anuel AA\n",
       "1  Childish Gambino   This Is America\n",
       "2            Tydiaz  Foire de Châlons"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist.drop(columns=[\"Naissance\", \"Pays d'origine\", \"Origine\", \"Pays\", \"Nationalité\"], inplace=True)\n",
    "artist.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist.drop(columns=[\"Artist_wiki\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2004, 2023, 1)\n",
    "weeks = [int(v) for v in np.linspace(1, 52, 12)]\n",
    "mois = [\"Janvier\", \"Fevrier\", \"Mars\", \"Avril\", \"Mai\", \"Juin\", \"Juillet\", \"Aout\", \"Septembre\", \"Octobre\", \"Novembre\", \"Decembre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [73], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m m \u001b[39m=\u001b[39m mois[k]\n\u001b[0;32m      7\u001b[0m \u001b[39mif\u001b[39;00m rq\u001b[39m.\u001b[39mok:\n\u001b[1;32m----> 8\u001b[0m     soup \u001b[39m=\u001b[39m BeautifulSoup(rq\u001b[39m.\u001b[39;49mtext)\n\u001b[0;32m     10\u001b[0m     chart \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39m\"\u001b[39m\u001b[39mChartTable\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[0;32m     11\u001b[0m     trs \u001b[39m=\u001b[39m chart\u001b[39m.\u001b[39mfindAll(\u001b[39m\"\u001b[39m\u001b[39mtr\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m:]\n",
      "File \u001b[1;32mc:\\Users\\quent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\__init__.py:333\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39minitialize_soup(\u001b[39mself\u001b[39m)\n\u001b[0;32m    332\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 333\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feed()\n\u001b[0;32m    334\u001b[0m     success \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\quent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\__init__.py:451\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39m# Convert the document to Unicode.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mreset()\n\u001b[1;32m--> 451\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mfeed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmarkup)\n\u001b[0;32m    452\u001b[0m \u001b[39m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendData()\n",
      "File \u001b[1;32mc:\\Users\\quent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\builder\\_htmlparser.py:399\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    397\u001b[0m parser\u001b[39m.\u001b[39msoup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoup\n\u001b[0;32m    398\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     parser\u001b[39m.\u001b[39;49mfeed(markup)\n\u001b[0;32m    400\u001b[0m     parser\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    401\u001b[0m \u001b[39mexcept\u001b[39;00m HTMLParseError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\quent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\html\\parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[39mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[39mas you want (may include '\\n').\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m+\u001b[39m data\n\u001b[1;32m--> 110\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgoahead(\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\quent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\html\\parser.py:170\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[1;34m(self, end)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m startswith(\u001b[39m'\u001b[39m\u001b[39m<\u001b[39m\u001b[39m'\u001b[39m, i):\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m starttagopen\u001b[39m.\u001b[39mmatch(rawdata, i): \u001b[39m# < + letter\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m         k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_starttag(i)\n\u001b[0;32m    171\u001b[0m     \u001b[39melif\u001b[39;00m startswith(\u001b[39m\"\u001b[39m\u001b[39m</\u001b[39m\u001b[39m\"\u001b[39m, i):\n\u001b[0;32m    172\u001b[0m         k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_endtag(i)\n",
      "File \u001b[1;32mc:\\Users\\quent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\html\\parser.py:300\u001b[0m, in \u001b[0;36mHTMLParser.parse_starttag\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m j\n\u001b[0;32m    299\u001b[0m \u001b[39m# Internal -- handle starttag, return end or -1 if not terminated\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_starttag\u001b[39m(\u001b[39mself\u001b[39m, i):\n\u001b[0;32m    301\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__starttag_text \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     endpos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_for_whole_start_tag(i)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dfs_chart = {y : {} for y in years}\n",
    "for y in tqdm(years):\n",
    "    for k, w in enumerate(weeks):\n",
    "        url = f\"https://acharts.co/france_singles_top_100/{y}/{w}\"\n",
    "        rq = get(url)\n",
    "        m = mois[k]\n",
    "        if rq.ok:\n",
    "            soup = BeautifulSoup(rq.text)\n",
    "\n",
    "            chart = soup.find(\"table\", {\"id\" : \"ChartTable\"})\n",
    "            trs = chart.findAll(\"tr\")[1:]\n",
    "\n",
    "            data = []\n",
    "            for tr in trs:\n",
    "                music_name = tr.find(\"span\", {\"itemprop\" : \"name\"}).text\n",
    "                rank = tr.find(\"span\", {\"itemprop\" : \"position\"}).text\n",
    "                artist_name = tr.find(\"span\", {\"itemprop\" : \"byArtist\"}).text[2:-1]\n",
    "                data.append([rank, artist_name, music_name])\n",
    "\n",
    "            df = pd.DataFrame(data, columns=[\"Rank\", \"Artist\", \"Music\"])\n",
    "            dfs_chart[y][m] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    (\"Djadja\", \"Djadja et Dinaz\"),\n",
    "    (\"Lorie\", \"Lorie Pester\"),\n",
    "    (\"-M-\", \"Matthieu Chedid\"),\n",
    "    (\"Priscilla\", \"Priscilla Betti\"),\n",
    "    (\"I Am\", \"IAM\"),\n",
    "    (\"Sofiane\", \"Sofiane Zermani\"),\n",
    "    (\"Justice\", \"Justice (groupe\"),\n",
    "    (\"Soma Riba\", \"Collectif Métissé\"),\n",
    "    (\"Fresh\", \"Fresh la Peufra\"),\n",
    "    (\"Rosalia\", \"Rosalía\"),\n",
    "    (\"Italo Brothers\", \"ItaloBrothers\"),\n",
    "    (\"Far*east Movement\", \"Far East Movement\"),\n",
    "    (\"Odyssey\", \"Odyssey (groupe)\"),\n",
    "    (\"1789\", \"1789 : Les Amants de la Bastille\"),\n",
    "    (\"Clemence\", \"Clémence Saint-Preux\"),\n",
    "    (\"C\\x9cUr De Pirate\", \"Cœur de pirate\"),\n",
    "    (\"Rose\", \"Rose (chanteuse)\"),\n",
    "    (\"Laeti\", \"Laetitia Kerfa\"),\n",
    "    (\"La Troupe\", \"Mozart, l'opéra rock\"),\n",
    "    (\"Victoria\", \"Victoria Sio\")\n",
    "    \n",
    "]\n",
    "\n",
    "for k1 in dfs_chart.keys():\n",
    "    for k2 in dfs_chart[k1].keys():\n",
    "        for n1, n2 in names:\n",
    "            dfs_chart[k1][k2].replace(n1, n2, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_title_in_wikipedia(title):\n",
    "    pourcentage = 0.7\n",
    "    words = [\"(chanteur)\", \"(chanteuse)\", \"(groupe)\", \"(rappeur)\", \"(rappeuse)\", \"(musicien)\", \"(chanteur français)\", \"(france)\", \"(producteur)\", \"(artiste)\", \"(groupe de musique)\"]\n",
    "\n",
    "    wikipedia.set_lang(\"fr\")\n",
    "    results = wikipedia.search(title, results=10)\n",
    "    distance = []\n",
    "    if len(results) > 0:\n",
    "        for element in results:\n",
    "            if any((w in element.lower()) and (edit_distance(element.lower().rstrip(w), title.lower())/len(title) < pourcentage) for w in words):\n",
    "                return element\n",
    "\n",
    "            distance.append(edit_distance(title.lower(), element.lower()))\n",
    "\n",
    "        return results[np.argmin(distance)] if min(distance)/len(title) <= pourcentage else MISSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_birth(title):\n",
    "    cols = [\"Naissance\", \"Pays d'origine\", \"Origine\", \"Nationalité\", \"Pays\"]\n",
    "    nats = [\"franco\", \"français\", \"belge\", \"canadien\", \"libanais\", \"réunionnais\"]\n",
    "    dic = {w : MISSING for w in cols}\n",
    "\n",
    "    if title == MISSING:\n",
    "        return dic\n",
    "\n",
    "    url = f\"https://fr.wikipedia.org/wiki/{title}\"\n",
    "    rq = get(url)\n",
    "\n",
    "    if not rq.ok:\n",
    "        return dic\n",
    "    \n",
    "    soup = BeautifulSoup(rq.text)\n",
    "    tables = soup.findAll(\"table\")\n",
    "\n",
    "    for table in tables:\n",
    "        trs = table.findAll(\"tr\")\n",
    "\n",
    "        for tr in trs:\n",
    "            th = tr.find(\"th\")\n",
    "\n",
    "            if th is not None:\n",
    "                for w in cols:\n",
    "                    if w in th.text:\n",
    "                        td = tr.find(\"td\")\n",
    "                        if td is not None:\n",
    "                            dic[w] = td.text.strip()\n",
    "\n",
    "    if not all(x == \" \" for x in dic.values()):\n",
    "        return dic\n",
    "    else:\n",
    "        wikipedia.set_lang(\"fr\")\n",
    "        try:\n",
    "            summary = wikipedia.summary(title, sentences=1)\n",
    "            for w in nats:\n",
    "                if w in summary:\n",
    "                    dic[\"Nationalité\"] = w\n",
    "                    return dic\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Récupére tous les artistes uniques\n",
    "artist = []\n",
    "for k1 in dfs_chart.keys():\n",
    "    for k2 in dfs_chart[k1].keys():\n",
    "        artist += dfs_chart[k1][k2][\"Artist\"].tolist()\n",
    "    \n",
    "artist = pd.DataFrame(list(set(artist)), columns=[\"Artist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist[\"Artist\"] = artist[\"Artist\"].str.split(\" X \").str[0] #Supprime les feat pour garder l'artiste principal\n",
    "artist[\"Artist_wiki\"] = artist[\"Artist\"].apply(find_title_in_wikipedia) #Trouve les pages wikipedia de chaque artistes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "birth_dic = artist[\"Artist_wiki\"].apply(wiki_birth) #Cherche les infos de naissance sur les pages wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforme les infos trouver sur wikipédia en dataframe\n",
    "dfs_birth = []\n",
    "for dic in birth_dic:\n",
    "    dfs_birth.append(pd.DataFrame(dic, index=[0]))\n",
    "birth = pd.concat(dfs_birth, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge les infos de naissance avec les infos des artistes\n",
    "artist = artist.merge(birth, left_index=True, right_index=True)\n",
    "artist = artist.set_index(\"Artist\")\n",
    "\n",
    "for k1 in dfs_chart.keys():\n",
    "    for k2 in dfs_chart[k1].keys():\n",
    "        dfs_chart[k1][k2] = dfs_chart[k1][k2].merge(artist, on=\"Artist\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEANNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = artist.columns.tolist()\n",
    "cols.remove(\"Naissance\")\n",
    "cols.remove(\"Artist_wiki\")\n",
    "\n",
    "for col in cols:\n",
    "    artist[col] = artist[col].apply(lambda x : x if len(x) < 50 else MISSING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanning(data, replace_words):\n",
    "    new_df = data.copy()\n",
    "    new_df = new_df.str.lower()\n",
    "    for w1, w2 in replace_words:\n",
    "        new_df[new_df.str.contains(w1)] = w2\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_words = [\n",
    "    (\"français\", \"française\"),\n",
    "    (\"franco\", \"française\"),\n",
    "    (\"canadien\", \"canadienne\"),\n",
    "    (\"américain\", \"américaine\"),\n",
    "    (\"états-unis\", \"américaine\"),\n",
    "    (\"algérien\", \"algérienne\"),\n",
    "    (\"brésil\", \"brésilienne\"),\n",
    "    (\"france\", \"française\"),\n",
    "    (\"marocain\", \"marocaine\"),\n",
    "    (\"anglais\", \"britannique\"),\n",
    "    (\"royaume-unis\", \"britannique\"),\n",
    "    (\"britannique\", \"britannique\"),\n",
    "    (\"espagn\", \"espagnole\"),\n",
    "    (\"italie\", \"italienne\"),\n",
    "    (\"japon\", \"japonaise\"),\n",
    "    (\"corée\", \"coréenne\"),\n",
    "    (\"israél\", \"israélienne\"),\n",
    "    (\"royaume-uni\", \"britannique\"),\n",
    "    (\"suède\", \"suédoise\"),\n",
    "    (\"allemand\", \"allemande\"),\n",
    "    (\"dominicain\", \"dominicaine\")\n",
    "]\n",
    "\n",
    "artist[\"Nationalité\"] = cleanning(artist[\"Nationalité\"], replace_words)\n",
    "artist[\"Origine\"] = cleanning(artist[\"Origine\"], replace_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_words = [\n",
    "    (\"france\", \"france\"),\n",
    "    (\"états-unis\", \"états-unis\"),\n",
    "    (\"royaume-uni\", \"royaume-unis\"),\n",
    "    (\"allemagne\", \"allemagne\"),\n",
    "    (\"angleterre\", \"angleterre\"),\n",
    "    (\"canada\", \"canada\"),\n",
    "    (\"australie\", \"australie\"),\n",
    "    (\"pays-bas\", \"pays-bas\"),\n",
    "    (\"ghana\", \"ghana\"),\n",
    "    (\"corée\", \"corée\"),\n",
    "    (\"autriche\", \"autriche\"),\n",
    "    (\"suède\", \"suède\"),\n",
    "    (\"italie\", \"italie\"),\n",
    "    (\"biélorussie\", \"biélorussie\"),\n",
    "    (\"mauritanie\", \"mauritanie\")\n",
    "]\n",
    "\n",
    "artist[\"Pays\"] = cleanning(artist[\"Pays\"], replace_words)\n",
    "artist[\"Pays d'origine\"] = cleanning(artist[\"Pays d'origine\"], replace_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Birthday case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1 in dfs_chart.keys():\n",
    "    for k2 in dfs_chart[k1].keys():\n",
    "        dfs_chart[k1][k2].to_csv(f\"../chart/{k1}_{k2}.csv\", encoding=\"utf-8-sig\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist.to_csv(\"../artist.csv\", encoding=\"utf-8-sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
